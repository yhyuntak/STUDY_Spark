{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1714e434",
   "metadata": {},
   "source": [
    "사용자는 **표현식**으로 DataFrame의 컬럼을 선택,조작,제거할 수 있다. 스파크에선 dataframe의 트랜스포메이션을 사용해야 컬럼 내용에 접근할 수 있다. \n",
    "\n",
    "# 1. 컬럼\n",
    "---\n",
    "\n",
    "컬럼 생성은 col/column 함수를 사용하는 것이 가장 간단하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dda411d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col,column\n\u001b[1;32m----> 3\u001b[0m col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\functions.py:152\u001b[0m, in \u001b[0;36mcol\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;241m1.3\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcol\u001b[39m(col: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    Returns a :class:`~pyspark.sql.Column` based on the given column name.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    Column<'x'>\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_invoke_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\functions.py:83\u001b[0m, in \u001b[0;36m_invoke_function\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke_function\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Invokes JVM function identified by name with args\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    and wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     jf \u001b[38;5;241m=\u001b[39m _get_jvm_function(name, SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jf(\u001b[38;5;241m*\u001b[39margs))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,column\n",
    "\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461e508",
   "metadata": {},
   "source": [
    "위 예제가 왜 에러가 뜨는지 모르겠다. \n",
    "\n",
    "# 2. 표현식\n",
    "---\n",
    "\n",
    "표현식은 DataFrame 레코드의 여러 값에 대한 트랜스포메이션 집합을 의미한다.\n",
    "\n",
    "# 3. 레코드와 로우\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d36a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "myRow=Row(\"hello\",None,1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b9dc4",
   "metadata": {},
   "source": [
    "# 4. DataFrame의 트랜스포메이션\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cf3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"session4\")\\\n",
    "    .config(\"spark.some.config.option\",\"some-value\")\\\n",
    "    .getOrCreate()\n",
    "df = spark.read.format(\"json\").load(\"../data/flight-data/json/2015-summary.json\")\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b60f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d569a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|hello|null|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField,StructType,StringType,LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"some\",StringType(),True),\n",
    "    StructField(\"col\",StringType(),True),\n",
    "    StructField(\"names\",LongType(),False)\n",
    "])\n",
    "myRow = Row(\"hello\",None,1)\n",
    "myDf = spark.createDataFrame([myRow],myManualSchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc162c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.2 select와 selectExpr\n",
    "\n",
    "df.select(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be9189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr,col,column\n",
    "\n",
    "df.select(expr(\"DEST_COUNTRY_NAME\"),col(\"DEST_COUNTRY_NAME\"),column(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f780484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e39d4021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|DEST_COUNTRY_NAME_new|\n",
      "+---------------------+\n",
      "|        United States|\n",
      "|        United States|\n",
      "+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\").alias(\"DEST_COUNTRY_NAME_new\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca1f72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|  destination|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select + expr = selectExpr\n",
    "df.selectExpr(\"DEST_COUNTRY_NAME as destination\",\"DEST_COUNTRY_NAME\").show(2) # 여러개를 선택하게 해주는 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de6ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 조건문도 사용 가능\n",
    "df.selectExpr(\n",
    "    \"*\",\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\"\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ade86b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n",
      "| avg(count)|count(DISTINCT DEST_COUNTRY_NAME)|\n",
      "+-----------+---------------------------------+\n",
      "|1770.765625|                              132|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 집계 함수 사용 가능\n",
    "df.selectExpr(\"avg(count)\",\"count(distinct(DEST_COUNTRY_NAME))\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2b85469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "|    United States|            Ireland|  344|  1|\n",
      "|            Egypt|      United States|   15|  1|\n",
      "|    United States|              India|   62|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 일정 값을 설정? 나열? 하는 함수 lit()\n",
    "from pyspark.sql.functions import lit\n",
    "df.select(expr(\"*\"),lit(1).alias(\"One\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b2a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 공식적인 컬럼 추가 메서드 withColumn\n",
    "\n",
    "df.withColumn(\"numberOne\",lit(1)).show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8ff5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "|    United States|            Ireland|  344|        false|\n",
      "|            Egypt|      United States|   15|        false|\n",
      "|    United States|              India|   62|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼의 표현식을 사용해서 나타낼 수도 있음.\n",
    "df.withColumn(\"withinCountry\",expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98a321f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼명 변경\n",
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\",\"destination\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea4fd686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|This Long Column-Name|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "|    United States|            Romania|   15|              Romania|\n",
      "|    United States|            Croatia|    1|              Croatia|\n",
      "|    United States|            Ireland|  344|              Ireland|\n",
      "|            Egypt|      United States|   15|        United States|\n",
      "|    United States|              India|   62|                India|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column명에 하이픈 \"-\" 혹은 공백 같은 예약 문자?가 들어간 경우, 표현식을 사용할 때 항상 백틱(`)을 사용하라.\n",
    "df_with_long_col_name = df.withColumn(\"This Long Column-Name\",expr(\"ORIGIN_COUNTRY_NAME\"))\n",
    "df_with_long_col_name.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc214505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|This Long Column-Name|\n",
      "+---------------------+\n",
      "|              Romania|\n",
      "|              Croatia|\n",
      "|              Ireland|\n",
      "|        United States|\n",
      "|                India|\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_long_col_name.selectExpr(\"`This Long Column-Name`\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "888c3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+\n",
      "|count|This Long Column-Name|\n",
      "+-----+---------------------+\n",
      "|   15|              Romania|\n",
      "|    1|              Croatia|\n",
      "|  344|              Ireland|\n",
      "|   15|        United States|\n",
      "|   62|                India|\n",
      "+-----+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.7 스파크는 대소문자를 구분하지 않는다.\n",
    "\n",
    "# 4.8 컬럼 제거\n",
    "df_with_long_col_name.drop(\"ORIGIN_COUNTRY_NAME\",\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e03b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count2|\n",
      "+-----------------+-------------------+-----+------+\n",
      "|    United States|            Romania|   15|    15|\n",
      "|    United States|            Croatia|    1|     1|\n",
      "|    United States|            Ireland|  344|   344|\n",
      "|            Egypt|      United States|   15|    15|\n",
      "|    United States|              India|   62|    62|\n",
      "+-----------------+-------------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.9 컬럼의 데이터 타입 변경하기 - cast() 메서드\n",
    "df.withColumn(\"count2\",col(\"count\").cast(\"string\")).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "554feff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.10 로우 필터링하기\n",
    "\n",
    "df.filter(col(\"count\")<2).show(2)\n",
    "df.where(\"count < 2\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0127e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러 필터를 적용할 때 (and 느낌인 듯.)\n",
    "\n",
    "df.where(\"count < 2\").where(col(\"ORIGIN_COUNTRY_NAME\") == \"Croatia\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40b36365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.11 중복되지 않은 고유한 로우 얻기 - distinct() 메서드\n",
    "\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\",\"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d09d13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.12 무작위 샘플 만들기\n",
    "\n",
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement,fraction,seed).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce001e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.13 임의 분할\n",
    "data_frame = df.randomSplit([0.25,0.75],seed)\n",
    "data_frame[0].count() > data_frame[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "548af1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 로우 합치기와 추가하기\n",
    "from pyspark.sql import Row\n",
    "schema =  df.schema\n",
    "newRows = [\n",
    "    Row(\"new 1\",\"other 1\",5),\n",
    "    Row(\"new 2\",\"other 2\",2),\n",
    "]\n",
    "parallelizaedRows = spark.sparkContext.parallelize(newRows)\n",
    "newDF = spark.createDataFrame(parallelizaedRows,schema)\n",
    "\n",
    "df.union(newDF)\\\n",
    ".where(\"count = 1\")\\\n",
    ".where(col(\"ORIGIN_COUNTRY_NAME\") != \"United States\")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34cc2164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.15 로우 정렬하기\n",
    "\n",
    "df.orderBy(col(\"count\").desc(),col(\"DEST_COUNTRY_NAME\").asc()).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760fa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
